{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "790049fd-b240-4a1b-97b6-69d518f854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "import opendatasets as od\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af065ae-b56e-4071-ae2f-7e3abe6bd694",
   "metadata": {},
   "source": [
    "### Donwload and save dataset from Kaggle. \n",
    "#### Note: You need to have kaggle.json in the folder with this notebook or enter your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cdf56fe-08fc-4c10-96de-a529d06b93bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./ecommerse\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://www.kaggle.com/datasets/min02yam/ecommerse\"\n",
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31eb74-73ec-4cdf-a490-8ae4407ec646",
   "metadata": {},
   "source": [
    "### Getting dataset internal path and initializing PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f6fcce-3c73-4ed2-9920-0e446738dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_path = os.path.join(\"ecommerse\", os.listdir(\"ecommerse\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c543b0c-3ced-406c-a1b1-113d015e4896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/20 23:08:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/20 23:08:45 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Parsing ecommerse dataset\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ca976-7397-4d9f-95a9-684bf84dcb1c",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n",
    "- #### Adding a new column with Date (without time)\n",
    "- #### Calculate the total spent per item per invoice (UntiPrice * Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62fe2aa0-4eb7-4ac1-a7ed-bca742c4619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(dataset_file_path, header=True)\n",
    "spark.conf.set('spark.sql.legacy.timeParserPolicy', 'LEGACY')\n",
    "df = df.withColumn(\"DateOnly\", to_date(col(\"Date\"), \"MM/dd/yyyy HH:mm\"))\n",
    "df = df.withColumn(\"TotalPerItem\", round(col(\"UnitPrice\")*col(\"Quantity\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf462e-2071-4245-af52-2e1a79c0c255",
   "metadata": {},
   "source": [
    "### The number of transactions (inque Invoices) per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e47ae926-779b-4785-b6b2-032215dcb6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+\n",
      "|Year|Week|Invoices|\n",
      "+----+----+--------+\n",
      "|2010|  48|     348|\n",
      "|2010|  49|     449|\n",
      "|2010|  50|     381|\n",
      "|2010|  51|     105|\n",
      "|2011|   1|     221|\n",
      "|2011|   2|     220|\n",
      "|2011|   3|     199|\n",
      "|2011|   4|     270|\n",
      "|2011|   5|     257|\n",
      "|2011|   6|     205|\n",
      "|2011|   7|     256|\n",
      "|2011|   8|     248|\n",
      "|2011|   9|     256|\n",
      "|2011|  10|     251|\n",
      "|2011|  11|     279|\n",
      "|2011|  12|     281|\n",
      "|2011|  13|     299|\n",
      "|2011|  14|     282|\n",
      "|2011|  15|     324|\n",
      "|2011|  16|     248|\n",
      "+----+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(year(\"DateOnly\").alias(\"Year\"), weekofyear(\"DateOnly\").alias(\"Week\")).agg(countDistinct(\"InvoiceNo\").alias(\"Invoices\")).orderBy(\"Year\", \"Week\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24fa65f-b4d3-4531-a7a6-ee15b764599c",
   "metadata": {},
   "source": [
    "### The most active users by number of Invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a2f26a2-0d89-4510-b2ad-707401732b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| User|Invoices|\n",
      "+-----+--------+\n",
      "|14911|     206|\n",
      "|12748|     173|\n",
      "|17841|     136|\n",
      "|15311|     107|\n",
      "|14606|     105|\n",
      "|13089|      90|\n",
      "|14646|      64|\n",
      "|14527|      61|\n",
      "|14156|      55|\n",
      "|12971|      52|\n",
      "|13408|      49|\n",
      "|13694|      46|\n",
      "|15039|      45|\n",
      "|13798|      44|\n",
      "|16029|      43|\n",
      "|18102|      41|\n",
      "|16422|      40|\n",
      "|17511|      39|\n",
      "|17811|      39|\n",
      "|12921|      37|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(col(\"CustomerID\").alias(\"User\")).agg(countDistinct(\"InvoiceNo\").alias(\"Invoices\")).orderBy(desc(\"Invoices\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455dd8f-2115-4476-b1c8-c1b8b5535c95",
   "metadata": {},
   "source": [
    "### The most valuable users by total spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf01b36a-10ac-406f-b0e3-1c6d7f0b48c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "| User|TotalySpent|\n",
      "+-----+-----------+\n",
      "|14646|    71371.0|\n",
      "|18102|    58466.0|\n",
      "|17450|    42392.0|\n",
      "|15098|    39917.0|\n",
      "|12415|    33578.0|\n",
      "|14911|    29448.0|\n",
      "|14156|    26878.0|\n",
      "|17949|    19870.0|\n",
      "|17511|    19352.0|\n",
      "|16684|    16785.0|\n",
      "|14096|    15961.0|\n",
      "|13694|    14454.0|\n",
      "|13089|    14337.0|\n",
      "|14298|    13222.0|\n",
      "|15311|    13147.0|\n",
      "|14088|    13022.0|\n",
      "|15061|    12683.0|\n",
      "|15769|    11589.0|\n",
      "|17841|     9674.0|\n",
      "|15838|     9627.0|\n",
      "+-----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(col(\"CustomerID\").alias(\"User\")).agg(sum(\"TotalPerItem\").alias(\"TotalySpent\")).orderBy(desc(\"TotalySpent\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b63d2-78a1-44d5-b5c0-baba022582a3",
   "metadata": {},
   "source": [
    "### Top 10 the most popul (buyable) product per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41868d9a-567f-45c2-8bef-217c55b5cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------+------+----+\n",
      "|Year|Week|Product|SoldNo|Rank|\n",
      "+----+----+-------+------+----+\n",
      "|2010|  48|  84077|3216.0|   1|\n",
      "|2010|  48| 17084R|1440.0|   2|\n",
      "|2010|  48|  22616| 676.0|   3|\n",
      "|2010|  48|  21137| 480.0|   4|\n",
      "|2010|  48|  21731| 458.0|   5|\n",
      "|2010|  48|  84879| 429.0|   6|\n",
      "|2010|  48| 85099B| 336.0|   7|\n",
      "|2010|  48|  84347| 311.0|   8|\n",
      "|2010|  48|  22865| 285.0|   9|\n",
      "|2010|  48|  21212| 246.0|  10|\n",
      "|2010|  49|  17096|1728.0|   1|\n",
      "|2010|  49|  22328|1494.0|   2|\n",
      "|2010|  49| 85099B| 631.0|   3|\n",
      "|2010|  49|  21623| 600.0|   4|\n",
      "|2010|  49|  22469| 481.0|   5|\n",
      "|2010|  49|  22867| 455.0|   6|\n",
      "|2010|  49|  22470| 432.0|   7|\n",
      "|2010|  49|  84945| 420.0|   8|\n",
      "|2010|  49|  22659| 339.0|   9|\n",
      "|2010|  49|  20668| 312.0|  10|\n",
      "+----+----+-------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.groupBy(year(\"DateOnly\").alias(\"Year\"), weekofyear(\"DateOnly\").alias(\"Week\"), col(\"ProductNo\").alias(\"Product\")).agg(sum(\"Quantity\").alias(\"SoldNo\"))\n",
    "w = Window.partitionBy(df2[\"Year\"], df2[\"Week\"]).orderBy(df2[\"SoldNo\"].desc())\n",
    "df2.select(\"*\", rank().over(w).alias(\"Rank\")).filter(col(\"Rank\") <= 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4479bc-877d-4dbc-962d-251e52495703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
